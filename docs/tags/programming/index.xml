<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Programming on</title><link>/tags/programming/</link><description> (Programming)</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Tue, 28 Jan 2025 19:46:23 -0500</lastBuildDate><atom:link href="/tags/programming/index.xml" rel="self" type="application/rss+xml"/><item><title>The Penultimate Wave of AI</title><link>/blog/the-penultimate-wave-of-ai/</link><pubDate>Tue, 28 Jan 2025 19:46:23 -0500</pubDate><guid>/blog/the-penultimate-wave-of-ai/</guid><description>&lt;p>I don&amp;rsquo;t think &lt;a href="https://github.com/deepseek-ai/DeepSeek-R1">r1&lt;/a> will get us to artificial super intelligence, but whatever comes next probably will.&lt;/p>
&lt;p>We are reaching a familiar bottleneck in AI. Previously, humans had to manually hardcode the patterns that AI could recognize. With deep learning, machines began to learn patterns on their own, without human assistance. With (relatively) expensive humans out of the loop, we threw machines at the world&amp;rsquo;s data until they began to talk, code, and paint. Many people believed this would be sufficient to reach artificial super intelligence&amp;ndash;but it wasn&amp;rsquo;t.&lt;/p>
&lt;p>We ran out of data. Luckily, our newborn bots could talk 24/7&amp;ndash;not just to hundreds of millions of people, but also to other programs. These programs would ask the bots questions, verify their answer, and then use the correct answers to further improve the models. Free, infinite data. If the world&amp;rsquo;s data wasn&amp;rsquo;t enough, then infinite data must be&amp;ndash;but it wasn&amp;rsquo;t.&lt;/p>
&lt;p>We are now watching the rise of reasoners&amp;ndash;models that &amp;ldquo;think&amp;rdquo; before giving an answer. Models which generate a series of words to raise the probability of eventually producing something we want. Surely, &lt;em>surely&lt;/em>, this is it. Once we train a model to reason, it will be able to reason about its own answers, and somehow, magically, self-improve.&lt;/p>
&lt;p>This infinite self-improvement probably won&amp;rsquo;t happen. In the same way that a fixed amount of mass can&amp;rsquo;t produce infinite energy, I suspect a fixed amount of information can&amp;rsquo;t produce infinite intelligence, no matter how much we feed it back into itself. Fundamentally, a model needs information from the outside, whether that information is a response from an external system or a human filtering its prior output for quality.&lt;/p>
&lt;p>We provide some external information using formal verification systems, which is why math and programming performace is the &lt;a href="https://openai.com/index/learning-to-reason-with-llms/">prominent flex&lt;/a> from the latest models. But most domains, like biology, business, and rocket science, are not so lucky; the correct answer is rarely obvious, even for programming. How does one automatically verify an interface is easy to use?&lt;/p>
&lt;p>The answer still comes down to humans. Much to the dismay of a few arrogant men in San Francisco, people are still a key ingredient. This time, we don&amp;rsquo;t merely tell machines what patterns to look for; rather, we filter synthetic data to &amp;ldquo;steer&amp;rdquo; the model towards answers we prefer, i.e, we tell them what patterns to look for, but cheaper.&lt;/p>
&lt;p>At this point, if the right mixture of curated data could yield superintelligence, it would have&amp;ndash;models are now &lt;a href="https://arxiv.org/abs/2501.12948v1">crushing benchmarks which PhDs struggle on&lt;/a>. This is ridiculous. We&amp;rsquo;re going to wring these models of performance until they&amp;rsquo;re dry, and even then they won&amp;rsquo;t be superintelligent. Aside from extending formal verification, the way forward still seems to be curating the reasoning data these models generate and feeding it back in. As chains of reasoning become longer and more complex, human-curated data will likely yield increasingly diminishing returns.&lt;/p>
&lt;p>We&amp;rsquo;ll be approaching the limit of what these systems can do. Don&amp;rsquo;t get me wrong, they can do a &lt;em>lot&lt;/em>&amp;ndash;they&amp;rsquo;re basically magic&amp;ndash;but they can&amp;rsquo;t generally self-improve without humans or verifiers. And honestly, I can&amp;rsquo;t imagine what else comes next besides self-improving AI. We don&amp;rsquo;t know what that looks like&amp;ndash;maybe some &lt;a href="https://puffer.ai/">multiagent game-playing system&lt;/a>&amp;ndash;but whatever it is, it will be the last. For real, this time. Probably.&lt;/p></description></item><item><title>Reducing Code Complexity using UI</title><link>/blog/reducing-code-complexity-using-ui/</link><pubDate>Fri, 15 Nov 2024 07:01:30 -0800</pubDate><guid>/blog/reducing-code-complexity-using-ui/</guid><description>&lt;p>I&amp;rsquo;m doing an internship right now, and thankfully, I read a few books on software design before starting.&lt;/p>
&lt;p>I had to design a database schema, data submission page, submission approval page, and dynamic dashboard for the project I was assigned to. This is one of those projects that AI can obviously do 90% of to work for if designed appropriately&amp;ndash;if the right abstractions are used, performance trade-offs are made, and the right tools are chosen. I wanted to make sure that, throughout the project, AI could always easily with any part of the codebase.&lt;/p>
&lt;p>For AI, code simplicity is a non-negotiable. Your code needs to be small, modular and clear, full stop. AI doesn&amp;rsquo;t work well with complex code bases with many unfamiliar datastructures across multiple files yet, so one goal was limit the codebase for each webpage to a single file, and for that file to be as small as possible, which worked really well. Being able to copy+paste your entire codebase into ChatGPT is very powerful.&lt;/p>
&lt;p>We wanted to implement features such that the user would never end up in a slightly unintuitive state, specifically, we didn&amp;rsquo;t want users to normalize data by a series and view the data in log scale simultaneously. The issue is, given our tooling, it would take a decent chunk of code (relative to our codebase) to make it impossible to end up in such a state, and would require some logic to manage which action they took first. Did they normalize first, then try to view in log scale? Or did they try to view in log scale, and then normalize? What should take priority? What does the user expect?&lt;/p>
&lt;p>Instead of increasing the complexity and control flow to handle this, I instead tried to first make it clear to the user exactly what state they were in. We added a large, visible red X to the normalization dropdown to draw the user&amp;rsquo;s attention to the &amp;ldquo;Clear Normalization Series&amp;rdquo; option, which resets the chart to the absolute values, instead of relative. From the user perspective, this makes it clear when you are working with normalized data, so when you view in log scale, you know what you&amp;rsquo;re looking at, and can decide for yourself what view you want to see. If you want to see something unintuitive, no biggie, it&amp;rsquo;s obvious what you are looking at. The &amp;ldquo;Make the X big and Red&amp;rdquo; commit was a couple lines of CSS.&lt;/p>
&lt;p>For a &amp;ldquo;Graph Builder&amp;rdquo; feature, we initially planned to add a large number of buttons, dropdowns, and toggles to the UI elements so users can specify which types of data they want to view, and how they want to filter it. Adding the UI elements for each field would be a complexity nightmare, since we have a growing number of fields, many of which have missing data. However, we know our users are not our customers but rather internal employees, who have no other choice but to use our tool, and can afford a bit of a learning curve, since they will likely be using it for a while.&lt;/p>
&lt;p>Instead of adding potentially hundreds of lines of UI code/ callbacks, default options, and graceful handling of incompatible conditions, our solution is simply to allow users to specify a custom MongoDB query to fetch the data they want to visualize. This is the most powerful option, as it easily gives our users any view they desire, but it also requires that they know the database schema, which is annoying, even for me, the guy who made designed it.&lt;/p>
&lt;p>To make this feature user-friendly, we added a small &amp;ldquo;Show Query&amp;rdquo; button to all existing charts, so users can easily copy and maste queries used for existing graphs, gaining exposure to some of the fields and valies in the schema. This is a good start, but it&amp;rsquo;s still annoying to remember what additional fields are available, and what the current options are. This dashboard will have a tiny number of users and a modest amount of data, so what we can actually do, is run the working textarea query on each keystroke (if it&amp;rsquo;s valid) and, if no data is found, find out which values/fields don&amp;rsquo;t exist in the schema, and dynamically update a message below the text area with a list of existing entries which the user can type, all of which are easy to read. This too is a few extra lines of code, but allows the user to easily discover any field or value they want to use as they are typing the query. As a bonus, it allows users to save custom views in plain text as a MongoDB query, if they want to save or share them.&lt;/p>
&lt;p>By rethinking how we conveyed information to the user, we avoided increasing the complexity of our codebase in the first place. This approach doesn&amp;rsquo;t apply to all scenarios, especially if your users are paying customers, but it&amp;rsquo;s great when it does.&lt;/p></description></item><item><title>Upwards Pressure on Originality</title><link>/blog/upwards-pressure-on-originality/</link><pubDate>Sat, 05 Oct 2024 09:23:29 -0700</pubDate><guid>/blog/upwards-pressure-on-originality/</guid><description>&lt;p>It used to be good enough just to copy others. Now, with AI in the hands of billions, there&amp;rsquo;s little value in copying.&lt;/p>
&lt;p>For instance, take programming. Five years ago, building apps, websites, or games required a non-trivial amount of skill, and getting your first project off the ground was an accomplishment. Now, AI can generate most starter projects in hours, if not minutes. I think this decimates the reward, both internal and external, of actually completing the first few projects.&lt;/p>
&lt;p>First, it&amp;rsquo;s less impressive, which, in my opinion, matters. We like the feeling of pride we get when we show our work to others, especially when just starting out. It&amp;rsquo;s sad to diminish the relative value of someone&amp;rsquo;s work when they are just starting.&lt;/p>
&lt;p>Second, it&amp;rsquo;s less satisfying for us. For those who just want to build useful tools, modern technology is great. But, for those who want to feel a sense of reward for creating something, it&amp;rsquo;s sad, I think. There&amp;rsquo;s still lots to build, but for most projects, especially starter projects, the internal payoff&amp;rsquo;s been greatly diminished.&lt;/p>
&lt;p>This might have long-term consequences, because to get to the point where you can build something truly original, you first have to build many things which are unoriginal. The end goal of making something new is still just as valuable, if not more so, but the journey to develop the skills and original voice seems more mundane than ever. I also suspect that the next generation, who learns from AI will be significantly less technically competent, as they may never need to understand the technology they are working with.&lt;/p>
&lt;p>I think this will place an upwards pressure on originality and novelty. Now that both the technical barrier to entry and the cost of producing unoriginal work is so low, society will start to value original ideas more than ever&amp;ndash;doubly so if we reduce the rewards of the journey towards becoming original and skilled. If the world becomes flooded with less original, less technical users of AI, the value of technical competence and originality will skyrocket.&lt;/p></description></item><item><title>Emergent Trade and Tolerated Theft Using Multi-Agent Reinforcement Learning</title><link>/blog/emergent-trade/</link><pubDate>Sun, 04 Feb 2024 12:14:25 -0500</pubDate><guid>/blog/emergent-trade/</guid><description>&lt;p>I&amp;rsquo;ve been an author on a few papers before, but I recently published the first research project where I was responsible for most of the work and direction. It&amp;rsquo;s in the first 2024 issue of the journal &lt;em>Artificial Life&lt;/em>, which you can find &lt;a href="https://direct.mit.edu/artl/article-abstract/doi/10.1162/artl_a_00423/119154/Emergent-Resource-Exchange-and-Tolerated-Theft">here&lt;/a>. You can find a non-paywalled version &lt;a href="../../trade-paper.pdf">here&lt;/a> Below, I tell the chronology of the project and summarize our findings.&lt;/p>
&lt;p>&lt;img src="../../trade.gif" alt="Emergent Trade" loading="lazy">
&lt;/p>
&lt;p>We explore the conditions under which trade can emerge between four deep reinforcement learning agents that pick up and put down resources in a 2D foraging environment. Agents are rewarded for having both resources once, but the resources are distributed far apart from each other. To maximize reward, agents need to split up the work - agent 1 goes to resource A, agent 2 goes to resource B, etc, and then they meet to exchange resources, since meeting halfway can get them the most of each resource in the shortest amount of time.&lt;/p>
&lt;p>I was working on this for a while in isolation, getting nowhere, and slowly going crazy. A few months later, Deepmind published a &lt;a href="https://arxiv.org/abs/2205.06760">paper&lt;/a> that explored this exact behavior&amp;mdash;and found that agents could not discover how to exchange goods without programming a trading system into the game mechanics directly. I was getting similar results, but found that this trading behavior could emerge if I rewarded agents for being physically close to one another, which we&amp;rsquo;ll call a &amp;ldquo;community bonus&amp;rdquo;.&lt;/p>
&lt;p>I reached out to the authors (great people btw), and they hypothesized that the trading behavior was a result of agents trying to keep each other alive to get the community bonus. In my setup, agents could die if they ran out of resources, so they were also keeping each other alive for company. The authors suggested I add some sort of &amp;ldquo;market&amp;rdquo;, a place for agents to meet up and trade without getting directly rewarded for giving away resources for free.&lt;/p>
&lt;p>They explored similar ideas in their work, and if they couldn&amp;rsquo;t get this behavior to emerge, what chance did I have? I needed to try something similar but sufficiently different.&lt;/p>
&lt;p>Instead of adding a market where agents could come and go as they please, I added a campfire and a day-night cycle. I gave negative reward to agents for being out in the dark, which incentivizes them to gather around the campfire near others. Agents would only have enough time during the day to forage a single resource.&lt;/p>
&lt;p>As it turns out, agents really, &lt;em>really&lt;/em> don&amp;rsquo;t want to learn this behavior. It&amp;rsquo;s easy for agents to get cheated out of the resources they offer by others who offer nothing in return, so they gather as much as possible on their own. They even forage at night if the darkness penalty isn&amp;rsquo;t severe enough.&lt;/p>
&lt;p>Eventually, after 4+ days of training time, agents start to realize that working together isn&amp;rsquo;t so bad and land on a trading protocol where agents stand back, drop an offer, then walk over to collect the resources dropped by others. Experiments show that agents keep their distance initially so they can reclaim their offer if their trading partner attempts to cheat them.&lt;/p>
&lt;p>In one trial, agents converge on a local minimum, where agents 1&amp;amp;2 go to the same area to collect resource A, agent 3 goes to collect resource B, and agent 4 collects a bit of the other remaining resources. In this setting, we notice a behavior which we dub &amp;ldquo;Tolerated Theft&amp;rdquo;. When agent 1 collects significantly more of resource A than agent 2, agent 2 tries to steal the resources exchanged between agents 1 and 3. To defend against this, agent 1 will drop some resources away from agent 3, to get agent 2 off their backs while they trade. This is particularly interesting, because an agent manages to &amp;ldquo;steal&amp;rdquo; resources without us adding a combat or larceny system. Nature truly does find a way.&lt;/p>
&lt;p>I recommend checking out the &lt;a href="https://arxiv.org/abs/2307.01862">arxiv pre-print&lt;/a> if you are interested in the details and figures.&lt;/p></description></item><item><title>Take the Road Most Documented</title><link>/blog/take-the-road-most-documented/</link><pubDate>Sun, 28 Jan 2024 02:52:33 -0400</pubDate><guid>/blog/take-the-road-most-documented/</guid><description>&lt;p>How great would it be if the solution to most errors you face were in the first place you looked? That&amp;rsquo;s what the &lt;a href="https://wiki.archlinux.org/">Arch Wiki&lt;/a> has been for me: a massive wealth of information and troubleshooting resources to help me navigate the various configuration and installation issues I&amp;rsquo;ve encountered. Some people claim Arch Linux is too difficult for new users, but for me it&amp;rsquo;s been the only distribution I&amp;rsquo;ve been able to get consistently working, and it&amp;rsquo;s all thanks to the detailed documentation and known workarounds.&lt;/p>
&lt;p>I used to run a Dell XPS 9560, and have tried and failed to install Ubuntu and Manjaro on multiple occassions. Sometimes, the automatic installers would fail, other times they would succeed but install a broken configuration, leaving me with networking configurations that would crash as much as it would connect&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. However, when installing Arch, I resolved each installation error with the help of the wiki, so that by the time I was in a graphical desktop environment, everything was running smoothly.&lt;/p>
&lt;p>When I got my next laptop, I looked on the arch wiki to make sure there would be as few issues as possible setting up Linux&amp;mdash;and I faced none when installing.&lt;/p>
&lt;p>I love exciting, and popular, and &lt;em>new&lt;/em> software, but installing Arch showed me that &lt;em>popular&lt;/em> isn&amp;rsquo;t as important as &lt;em>understandable&lt;/em>. Software will always break; I don&amp;rsquo;t think there isn&amp;rsquo;t a single program I use daily whose configuration I haven&amp;rsquo;t broken at some point. But when I encounter an installation error, or a feature isn&amp;rsquo;t working, or I need to use a program for an unintended purpose, choosing programs with extensive documentation and active community resources has always saved me a headache.&lt;/p>
&lt;p>I use Hugo to generate this website. It&amp;rsquo;s so well documented (and there are bountiful answers on StackOverflow) that not only can I usually find the answer to the thing I want to do in the first few search results, but GPT-4 can often make a specific change I want too.&lt;/p>
&lt;p>With all else equal, take the road most documented.&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>This was before 2020, I&amp;rsquo;m sure these issues are largely fixed by now&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Numerical Stability in Flash Attention</title><link>/blog/numerical-stability-in-flash-attention/</link><pubDate>Thu, 27 Jul 2023 14:21:08 -0400</pubDate><guid>/blog/numerical-stability-in-flash-attention/</guid><description>&lt;p>&lt;a href="https://hazyresearch.stanford.edu/blog/2023-01-12-flashattention-long-sequences">Flash attention&lt;/a>, a recent implementation of attention which makes less calls
to high-bandwidth memory, uses a version of the softmax function which is numerically stable. In this post, I&amp;rsquo;ll briefly showcase how this is done and an example of an unstable softmax.&lt;/p>
&lt;p>The softmax function is used in machine learning to convert a vector of
real numbers to a vector of probabilities which sum to 1, and is defined as:&lt;/p>
&lt;pre>&lt;code>softmax(x) = [exp(x[i]) / sum([exp(xj) for xj in x]) for xi in x]
&lt;/code>&lt;/pre>
&lt;p>where x is a vector of real numbers.&lt;/p>
&lt;p>The python implementation below is numerically unstable because it involves
exponentiation of large numbers, which can lead to overflow. Crucially,
underflow is not an issue, because exp(x) approaches zero when x is a large
negative number.&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#b6a0ff">import&lt;/span> numpy &lt;span style="color:#b6a0ff">as&lt;/span> np
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#b6a0ff">def&lt;/span> &lt;span style="color:#feacd0">unstable_softmax&lt;/span>(x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fx_unstable &lt;span style="color:#00d3d0">=&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>exp(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#b6a0ff">return&lt;/span> fx_unstable &lt;span style="color:#00d3d0">/&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>sum(fx_unstable)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>The following implementation is stable however, because there is no
exponentiation of large numbers:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#b6a0ff">def&lt;/span> &lt;span style="color:#feacd0">stable_softmax&lt;/span>(x):
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> fx_stable &lt;span style="color:#00d3d0">=&lt;/span> x &lt;span style="color:#00d3d0">-&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>max(x)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> &lt;span style="color:#b6a0ff">return&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>exp(fx_stable) &lt;span style="color:#00d3d0">/&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>sum(np&lt;span style="color:#00d3d0">.&lt;/span>exp(fx_stable))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Instead, the max of the vector is subtracted from each element. This does not
change the result of the softmax after the division as this subtraction is also
performed in the denominator, thus cancelling out.&lt;/p>
&lt;p>Let&amp;rsquo;s compare the two implementations:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> a &lt;span style="color:#00d3d0">=&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>array([&lt;span style="color:#00bcff">6.0&lt;/span>, &lt;span style="color:#00d3d0">-&lt;/span>&lt;span style="color:#00bcff">3&lt;/span>, &lt;span style="color:#00bcff">15&lt;/span>], dtype&lt;span style="color:#00d3d0">=&lt;/span>np&lt;span style="color:#00d3d0">.&lt;/span>float32)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> stable_softmax(a)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#00bcff">1.2339458e-04&lt;/span> &lt;span style="color:#00bcff">1.5228101e-08&lt;/span> &lt;span style="color:#00bcff">9.9987662e-01&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> unstable_softmax(a)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[&lt;span style="color:#00bcff">1.2339458e-04&lt;/span> &lt;span style="color:#00bcff">1.5228101e-08&lt;/span> &lt;span style="color:#00bcff">9.9987656e-01&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>As you can see, the results are mostly equal, save for a few digits.
Now let&amp;rsquo;s look at what happens with 16 bits of precision:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> a &lt;span style="color:#00d3d0">=&lt;/span> np&lt;span style="color:#00d3d0">.&lt;/span>array([&lt;span style="color:#00bcff">6.0&lt;/span>, &lt;span style="color:#00d3d0">-&lt;/span>&lt;span style="color:#00bcff">3&lt;/span>, &lt;span style="color:#00bcff">15&lt;/span>], dtype&lt;span style="color:#00d3d0">=&lt;/span>np&lt;span style="color:#00d3d0">.&lt;/span>float16)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> unstable_softmax(a)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[ &lt;span style="color:#00bcff">0.&lt;/span> &lt;span style="color:#00bcff">0.&lt;/span> nan]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#00d3d0">&amp;gt;&amp;gt;&amp;gt;&lt;/span> stable_softmax(a)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>[ &lt;span style="color:#00bcff">1.234e-04&lt;/span> &lt;span style="color:#00bcff">0.000e+00&lt;/span> &lt;span style="color:#00bcff">1.000e+00&lt;/span>]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>When working with 16 bits of precision, we observe that exp(15) produces a numerical overflow
which turns the third element into a NaN. This is because exp(15) produces a value that can
not be represented by a float16.&lt;/p>
&lt;p>To recap, we showed that softmax is numerically unstable, especially when working with small precision bits. Because softmax uses exponentials in the numerator and denominator, we can subtract all exponents by the maximum exponent, constraining all the values between 0 and 1 and preventing numerical overflow.&lt;/p></description></item><item><title>Introducing Kittyplot</title><link>/blog/introducing-kittyplot/</link><pubDate>Sat, 20 May 2023 21:09:16 -0400</pubDate><guid>/blog/introducing-kittyplot/</guid><description>&lt;p>&lt;a href="https://github.com/jarbus/kittyplot">Kittyplot&lt;/a> is a program designed to plot experiment data in the kitty terminal using the &lt;a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/">kitty graphics protocol&lt;/a>, primarily for use on HPC clusters.&lt;/p>
&lt;p>&lt;img src="../../kittyplot-ex.gif" alt="Kittyplot example GIF" loading="lazy">
&lt;/p>
&lt;p>Plots are rendered using matplotlib, and users can zoom into different regions of the plots by setting x and y limits using their editor. I use &lt;a href="https://python-prompt-toolkit.readthedocs.io/en/master/index.html">prompt_toolkit&lt;/a> to accept regexp input and I override the tab-completion to instead display a list of all metrics that are matched by the current regexp.&lt;/p>
&lt;p>This will not be a well-maintained repo for the forseeable future and not a simple library one can &lt;code>pip install&lt;/code>. It&amp;rsquo;s merely a public copy of the script I use for visualizing experiment data over SSH without port-forwarding or running a web browser on my local machine. Kittyplot is only a few hunderd lines and is designed to be directly modified for user needs.&lt;/p>
&lt;p>I was initially inspired to make kittyplot when I got fed up with tensorboard taking 20+ minutes to load all the experiment data I was working with. I loved tensorboard solely for the purpose of monitoring metrics specified by a regexp, so I modified my experiments to stream all the metrics to a csv and wrote kittyplot to monitor them. Now, I can create, view, and save plots directly from my ssh connection.&lt;/p></description></item><item><title>Unexpected Benefits of Testing Code</title><link>/blog/unexpected-benefits-of-testing/</link><pubDate>Sat, 21 Jan 2023 18:38:43 -0500</pubDate><guid>/blog/unexpected-benefits-of-testing/</guid><description>&lt;p>Matthew Carlson&amp;rsquo;s blog post &lt;a href="https://matthewc.dev/musings/unit-tests/">&amp;ldquo;Fighting Distraction With Unit Tests&amp;rdquo;&lt;/a> inspired me to share some extra benefits of writing test code I&amp;rsquo;ve discovered during my PhD program.&lt;/p>
&lt;p>I&amp;rsquo;m working on a &lt;a href="https://github.com/jarbus/evotrade">weird project&lt;/a> that&amp;rsquo;s constantly changing as I try new things, and naturally, debugging and ensuring correctness was a nightmare. So I started writing tests, cursing myself for needing to write so much code I&amp;rsquo;ll likely throw away soon. But as it turns out, testing can be pretty helpful in a few other ways:&lt;/p>
&lt;ol>
&lt;li>When I encounter a bug I didn&amp;rsquo;t anticipate, I already have most of the code needed to reproduce it in a deterministic manner.&lt;/li>
&lt;li>When I want to add/change functionality, I already have most of the code needed ensure that my changes work.&lt;/li>
&lt;li>When writing new functionality, if I don&amp;rsquo;t already have the code needed to make ensure it&amp;rsquo;s working, I can write a small test that &lt;a href="https://timholy.github.io/Revise.jl/stable/user_reference/#Revise.entr">runs whenever my code changes&lt;/a>. Making this test case auto-run on a second screen dramatically reduces the amount of time spent switching windows and lets me stay in my editor until the test passes. I highly recommend setting up a run-on-change system, it makes writing tests or designing plots pretty fun.&lt;/li>
&lt;li>You can write tests for newer code by using tests for older code. This makes tests valuable as you develop, even if you plan to throw them out later.&lt;/li>
&lt;li>I feel more confident about what my code is actually doing. As someone who is working in AI, the value of this is immense, as AI code can run without crashing but still be subtly incorrect.&lt;/li>
&lt;/ol>
&lt;p>I&amp;rsquo;m not writing an exhaustive test suite, or tests for edge-cases that shouldn&amp;rsquo;t happen (asserts can deal with those). I&amp;rsquo;m writing code before I get bugs to spare myself the extra effort when I need to debug or make changes.&lt;/p></description></item></channel></rss>