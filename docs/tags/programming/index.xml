<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>programming on </title>
    <link>/tags/programming/</link>
    <description> (programming)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Jul 2023 14:21:08 -0400</lastBuildDate>
    
    <atom:link href="/tags/programming/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Numerical Stability in Flash Attention</title>
      <link>/blog/numerical-stability-in-flash-attention/</link>
      <pubDate>Thu, 27 Jul 2023 14:21:08 -0400</pubDate>
      
      <guid>/blog/numerical-stability-in-flash-attention/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://hazyresearch.stanford.edu/blog/2023-01-12-flashattention-long-sequences&#34;&gt;Flash attention&lt;/a&gt;, a recent implementation of attention which makes less calls
to high-bandwidth memory, uses a version of the softmax function which is numerically stable. In this post, I&amp;rsquo;ll briefly showcase how this is done and an example of an unstable softmax.&lt;/p&gt;
&lt;p&gt;The softmax function is used in machine learning to convert a vector of
real numbers to a vector of probabilities which sum to 1, and is defined as:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;softmax(x) = [exp(x[i]) / sum([exp(xj) for xj in x]) for xi in x]
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where x is a vector of real numbers.&lt;/p&gt;
&lt;p&gt;The python implementation below is numerically unstable because it involves
exponentiation of large numbers, which can lead to overflow. Crucially,
underflow is not an issue, because exp(x) approaches zero when x is a large
negative number.&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b6a0ff&#34;&gt;import&lt;/span&gt; numpy &lt;span style=&#34;color:#b6a0ff&#34;&gt;as&lt;/span&gt; np
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b6a0ff&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#feacd0&#34;&gt;unstable_softmax&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    fx_unstable &lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;exp(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#b6a0ff&#34;&gt;return&lt;/span&gt; fx_unstable &lt;span style=&#34;color:#00d3d0&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;sum(fx_unstable)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;The following implementation is stable however, because there is no
exponentiation of large numbers:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#b6a0ff&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#feacd0&#34;&gt;stable_softmax&lt;/span&gt;(x):
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    fx_stable &lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt; x &lt;span style=&#34;color:#00d3d0&#34;&gt;-&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;max(x)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#b6a0ff&#34;&gt;return&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;exp(fx_stable) &lt;span style=&#34;color:#00d3d0&#34;&gt;/&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;sum(np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;exp(fx_stable))
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Instead, the max of the vector is subtracted from each element. This does not
change the result of the softmax after the division as this subtraction is also
performed in the denominator, thus cancelling out.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s compare the two implementations:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; a &lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#00bcff&#34;&gt;6.0&lt;/span&gt;, &lt;span style=&#34;color:#00d3d0&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#00bcff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#00bcff&#34;&gt;15&lt;/span&gt;], dtype&lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;float32)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; stable_softmax(a)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[&lt;span style=&#34;color:#00bcff&#34;&gt;1.2339458e-04&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;1.5228101e-08&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;9.9987662e-01&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; unstable_softmax(a)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[&lt;span style=&#34;color:#00bcff&#34;&gt;1.2339458e-04&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;1.5228101e-08&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;9.9987656e-01&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;As you can see, the results are mostly equal, save for a few digits.
Now let&amp;rsquo;s look at what happens with 16 bits of precision:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#fff;background-color:#000;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; a &lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt; np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;array([&lt;span style=&#34;color:#00bcff&#34;&gt;6.0&lt;/span&gt;, &lt;span style=&#34;color:#00d3d0&#34;&gt;-&lt;/span&gt;&lt;span style=&#34;color:#00bcff&#34;&gt;3&lt;/span&gt;, &lt;span style=&#34;color:#00bcff&#34;&gt;15&lt;/span&gt;], dtype&lt;span style=&#34;color:#00d3d0&#34;&gt;=&lt;/span&gt;np&lt;span style=&#34;color:#00d3d0&#34;&gt;.&lt;/span&gt;float16)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; stable_softmax(a)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[ &lt;span style=&#34;color:#00bcff&#34;&gt;0.&lt;/span&gt;  &lt;span style=&#34;color:#00bcff&#34;&gt;0.&lt;/span&gt; nan]
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#00d3d0&#34;&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; unstable_softmax(a)
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;[ &lt;span style=&#34;color:#00bcff&#34;&gt;1.234e-04&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;0.000e+00&lt;/span&gt; &lt;span style=&#34;color:#00bcff&#34;&gt;1.000e+00&lt;/span&gt;]
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;When working with 16 bits of precision, we observe that exp(15) produces a numerical overflow
which turns the third element into a NaN. This is because exp(15) produces a value that can
not be represented by a float16.&lt;/p&gt;
&lt;p&gt;To recap, we showed that softmax is numerically unstable, especially when working with small precision bits. Because softmax uses exponentials in the numerator and denominator, we can subtract all exponents by the maximum exponent, constraining all the values between 0 and 1 and preventing numerical overflow.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introducing Kittyplot</title>
      <link>/blog/introducing-kittyplot/</link>
      <pubDate>Sat, 20 May 2023 21:09:16 -0400</pubDate>
      
      <guid>/blog/introducing-kittyplot/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://github.com/jarbus/kittyplot&#34;&gt;Kittyplot&lt;/a&gt; is a program designed to plot experiment data in the kitty terminal using the &lt;a href=&#34;https://sw.kovidgoyal.net/kitty/graphics-protocol/&#34;&gt;kitty graphics protocol&lt;/a&gt;, primarily for use on HPC clusters.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../kittyplot-ex.gif&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Plots are rendered using matplotlib, and users can zoom into different regions of the plots by setting x and y limits using their editor. I use &lt;a href=&#34;https://python-prompt-toolkit.readthedocs.io/en/master/index.html&#34;&gt;prompt_toolkit&lt;/a&gt; to accept regexp input and I override the tab-completion to instead display a list of all metrics that are matched by the current regexp.&lt;/p&gt;
&lt;p&gt;This will not be a well-maintained repo for the forseeable future and not a simple library one can &lt;code&gt;pip install&lt;/code&gt;. It&amp;rsquo;s merely a public copy of the script I use for visualizing experiment data over SSH without port-forwarding or running a web browser on my local machine. Kittyplot is only a few hunderd lines and is designed to be directly modified for user needs.&lt;/p&gt;
&lt;p&gt;I was initially inspired to make kittyplot when I got fed up with tensorboard taking 20+ minutes to load all the experiment data I was working with. I loved tensorboard solely for the purpose of monitoring metrics specified by a regexp, so I modified my experiments to stream all the metrics to a csv and wrote kittyplot to monitor them. Now, I can create, view, and save plots directly from my ssh connection.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Unexpected Benefits of Testing Code</title>
      <link>/blog/unexpected-benefits-of-testing/</link>
      <pubDate>Sat, 21 Jan 2023 18:38:43 -0500</pubDate>
      
      <guid>/blog/unexpected-benefits-of-testing/</guid>
      <description>&lt;p&gt;Matthew Carlson&amp;rsquo;s blog post &lt;a href=&#34;https://matthewc.dev/musings/unit-tests/&#34;&gt;&amp;ldquo;Fighting Distraction With Unit Tests&amp;rdquo;&lt;/a&gt; inspired me to share some extra benefits of writing test code I&amp;rsquo;ve discovered during my PhD program.&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;m working on a &lt;a href=&#34;https://github.com/jarbus/evotrade&#34;&gt;weird project&lt;/a&gt; that&amp;rsquo;s constantly changing as I try new things, and naturally, debugging and ensuring correctness was a nightmare. So I started writing tests, cursing myself for needing to write so much code I&amp;rsquo;ll likely throw away soon. But as it turns out, testing can be pretty helpful in a few other ways:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;When I encounter a bug I didn&amp;rsquo;t anticipate, I already have most of the code needed to reproduce it in a deterministic manner.&lt;/li&gt;
&lt;li&gt;When I want to add/change functionality, I already have most of the code needed ensure that my changes work.&lt;/li&gt;
&lt;li&gt;When writing new functionality, if I don&amp;rsquo;t already have the code needed to make ensure it&amp;rsquo;s working, I can write a small test that &lt;a href=&#34;https://timholy.github.io/Revise.jl/stable/user_reference/#Revise.entr&#34;&gt;runs whenever my code changes&lt;/a&gt;. Making this test case auto-run on a second screen dramatically reduces the amount of time spent switching windows and lets me stay in my editor until the test passes. I highly recommend setting up a run-on-change system, it makes writing tests or designing plots pretty fun.&lt;/li&gt;
&lt;li&gt;You can write tests for newer code by using tests for older code. This makes tests valuable as you develop, even if you plan to throw them out later.&lt;/li&gt;
&lt;li&gt;I feel more confident about what my code is actually doing. As someone who is working in AI, the value of this is immense, as AI code can run without crashing but still be subtly incorrect.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I&amp;rsquo;m not writing an exhaustive test suite, or tests for edge-cases that shouldn&amp;rsquo;t happen (asserts can deal with those). I&amp;rsquo;m writing code before I get bugs to spare myself the extra effort when I need to debug or make changes.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
