---
title: "Tesla and False Advertising in AI"
date: 2020-07-22T11:25:49-04:00
tags: ["technology", "ai"]
---
Here's the problem with advertising AI-based technology that doesn't exist:

 **You cannot promise anything about your product.**

We've all seen AI advertised to the masses that doesn't work as advertised, just look at any voice-to-text system. When I got my Apple Watch, I hoped to use it to respond to messages without getting distracted by my phone. I quickly realized that wasn't a viable solution: I had to repeat my message multiple times per text in order to get the correct dictation.

If this was a software issue, I could file a bug report and Apple could send out a fix. Unfortunately with AI, there isn't much Apple can do besides get more data and re-train the model, which still wouldn't guarantee a better user experience for anyone. Mind you, this is with software that's already shipped.

Now let's look at Tesla, or more specifically its CEO, Elon Musk. [Musk claims that Level 5 driving (in which a human is not needed behind the wheel) will be coming to Tesla vehicles in the form of a software update by the end of 2020](https://futurism.com/elon-musk-tesla-close-level-5-autonomy). A month before he made said claim, [a Tesla on autopilot crashed into a flipped truck](https://futurism.com/the-byte/tesla-autopilot-slam-overturned-truck)--a mistake most humans wouldn't make.

Just like Apple can't promise its speech-to-text system will work better than a human (or even better than a toddler), Musk can't guarantee anything about Tesla's Level 5 capability. Tesla can't even "reasonably claim" your car won't crash into flipped trucks or [stopped cop cars](https://www.msn.com/en-us/autos/enthusiasts/another-tesla-crashes-into-a-cop-car-while-on-autopilot/ar-BB16Mvkk#!). In fact, no one using deep learning can promise anything about their system. Deep learning, and by extension Tesla's Autopilot system, is a black box. We don't know why it works, we can't promise that it'll work, but it seems to work when we test it. Unless Tesla is testing on all roads in all conditions, they shouldn't even be "confident" level 5 technology, in which **a human does not need to be in the vehicle**, is "around the corner". That's why [a court in Germany banned Tesla from including “full potential for autonomous driving” and “Autopilot inclusive” in its German advertising materials](https://www.reuters.com/article/us-tesla-autopilot-germany/german-court-bans-tesla-ad-statements-related-to-autonomous-driving-idUSKCN24F1T5).

A Full Self-Driving (FSD) update wouldn't be the first time Tesla over-promises and under-delivers. Consumer Reports described the company's "Smart Summon" feature as ["glitchy and at times worked intermittently"](https://www.consumerreports.org/automotive-technology/teslas-smart-summon-performance-doesnt-match-marketing-hype/). The damage with Smart Summon has been low, but a full-autonomy update could result in a few consequences:

- Tesla sold cars with the promise of Level 5 driving in the future: Not only is Tesla now under immense pressure to rush out a Level 5 update as soon as possible, but must do so using the hardware it sold customers years ago. Hopefully Level 5 doesn't require LIDAR sensors (or any additional hardware) like Elon claims; because Tesla is expected to ship some version of FSD to users.
- Customers may end up in legal trouble if Tesla's software fails them: Tesla avoids legal responsibility for buggy software by shifting responsibility of an accident to the driver. However, when Tesla sells millions of cars on the premise that users won't have to manually drive them one day, should drivers be held responsible when that day comes and their car crashes?

Other companies have realized the high standards a Level 5 system should meet. Two years ago, [Waymo CEO John Krafcik claimed that true self-driving cars, that function everywhere under all circumstances, won't be ubiquitous for decades](https://www.bloomberg.com/news/articles/2018-11-13/waymo-ceo-says-self-driving-cars-won-t-be-ubiqitious-for-decades). As a result, Waymo shifted gears and placed its focus on rolling out [autonomous taxis](https://www.theverge.com/2019/12/9/21000085/waymo-fully-driverless-car-self-driving-ride-hail-service-phoenix-arizona) on a city by city basis, starting in Pheonix, Arizona. This approach to Level 5 driving is much safer for the following reasons:


- Waymo is minimizing the number of people at risk
- Waymo is operating its vehicles strictly where they have been tested.
- Waymo is not selling consumers a technology that doesn't exist
- Waymo is not relying on the average consumer to be attentive

Level 5 technology can save thousands of lives and millions of dollars--but it needs to be done to the same (if not higher) standards of automotive testing, and not the "move fast and break things" approach of Silicon Valley. Hopefully Tesla can safely deliver on its promise of full self driving soon, but if not, consumers may soon have a case to demand a refund.
